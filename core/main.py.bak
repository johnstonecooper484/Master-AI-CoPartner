from __future__ import annotations

from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv(), override=False)

"""main.py

Top-level entrypoint for the Master AI Co-Partner.
"""

from dataclasses import dataclass
import logging
import os
import time
from typing import Optional, Any, Dict

from core.io.speech.tts_local import LocalTTS
from config import settings
from core.logger import get_logger
from core.event_bus import EventBus
from core.memory.memory_manager import MemoryManager
from core.ai_engine import AIEngine
from core.hotkeys import start_hotkeys
from core.io.speech.listener import start_voice_listener
from core.intent_router import IntentRouter

# Hands (safe keyboard/mouse/app control)
from core.io.hands import Hands, HandsError

log = get_logger("core_main")


def _env_truthy(name: str, default: str = "0") -> bool:
    v = os.getenv(name, default).strip().lower()
    return v in {"1", "true", "yes", "y", "on"}


def _get_watch_detail() -> str:
    val = (os.getenv("COPARTNER_VISION_WATCH_DETAIL", "detailed") or "detailed").strip().lower()
    return "detailed" if val == "detailed" else "light"


def _get_watch_fps() -> float:
    raw = os.getenv("COPARTNER_VISION_WATCH_FPS", "1.0")
    try:
        fps = float(raw)
    except Exception:
        fps = 1.0
    if fps < 0.5:
        fps = 0.5
    if fps > 10.0:
        fps = 10.0
    return fps


def build_engine(
    offline_only: Optional[bool] = None,
    event_bus: Optional[EventBus] = None,
) -> AIEngine:
    """Factory to build the AIEngine with standard wiring."""
    bus = event_bus or EventBus()
    memory = MemoryManager()
    engine = AIEngine(event_bus=bus, memory=memory, offline_only=offline_only)
    return engine


def print_startup_banner(engine: AIEngine) -> None:
    mode = "OFFLINE" if engine.offline_only else "ONLINE-capable"
    print("=== Master AI Co-Partner ===")
    print(f"Active mode: {settings.ACTIVE_MODE}")
    print(f"Mode: {mode}")
    print("Type something and press Enter. Type 'quit' to exit.\n")
    print("Hands: try 'hands status' (hands are OFF by default)\n")


def interactive_loop(engine: AIEngine, preprocessor=None, *, tts: Optional[LocalTTS] = None, speak_cli: bool = True) -> None:
    """Very simple text-based UI.

    If speak_cli is True and tts is provided, typed replies are spoken out loud.
    """
    while True:
        try:
            text = input("You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("[Exiting Co-Partner main loop]")
            break

        if not text:
            continue
        if text.lower() in {"quit", "exit"}:
            print("[Goodbye from Co-Partner]")
            break

        # Pre-processor hook (used for 'hands ...' commands)
        if preprocessor is not None:
            handled = preprocessor(text)
            if handled is not None:
                print("AI:", handled)
                print()
                if speak_cli and tts is not None:
                    try:
                        tts.speak(str(handled))
                    except Exception:
                        log.exception("CLI TTS failed (handled reply)")
                continue

        reply = engine.process(text, {"source": "core_main_cli"})
        print("AI:", reply)
        print()
        if speak_cli and tts is not None and reply:
            try:
                tts.speak(str(reply))
            except Exception:
                log.exception("CLI TTS failed (engine reply)")


@dataclass
@dataclass
class VisionRuntimeState:
    memory_allowed: bool = False
    watch_enabled: bool = False
    last_image_path: Optional[str] = None
    last_source: Optional[str] = None
    _last_snapshot_log_monotonic: float = 0.0


def main() -> None:
    """Main entrypoint used by `python -m core.main`."""
    log.info("Starting Master AI Co-Partner core.main")

    # Reduce EventBus spam unless explicitly enabled.
    if not _env_truthy("COPARTNER_EVENTBUS_VERBOSE", "0"):
        logging.getLogger("event_bus").setLevel(logging.WARNING)

    # Shared EventBus
    bus = EventBus()

    # Core engine
    engine = build_engine(event_bus=bus)

    # Intent router (Think-Before-Speak gate)
    intent_router = IntentRouter()

    # Local TTS
    tts = LocalTTS()

    # Track vision state for wiring + debug
    vision_state = VisionRuntimeState()

    # Hands (safe OS control) - gated OFF by default
    hands = Hands()

    def maybe_handle_hands_command(text: str, *, source: str) -> Optional[str]:
        """
        Explicit-only Hands control.
        Trigger phrase must start with: 'hands ...'
        """
        t = (text or "").strip()
        low = t.lower().strip()
        if not low.startswith("hands"):
            return None

        parts = low.split()
        if len(parts) == 1:
            return "Try: hands status | hands enable | hands disable | hands open notepad | hands dryrun on/off"

        cmd = parts[1]

        try:
            if cmd == "status":
                st = hands.status()
                log.info("Hands status: %s", st)
                return f"Hands enabled={st['enabled']} dry_run={st['dry_run']} allowed_apps={', '.join(st['allowed_apps'])}"

            if cmd == "enable":
                hands.set_enabled(True)
                return "Hands enabled."

            if cmd == "disable":
                hands.set_enabled(False)
                return "Hands disabled."

            if cmd == "dryrun":
                if len(parts) < 3:
                    return "Usage: hands dryrun on | hands dryrun off"
                on = parts[2] in {"1", "on", "true", "yes"}
                hands.set_dry_run(on)
                return f"Hands dry-run set to {on}."

            if cmd == "open":
                if len(parts) < 3:
                    return "Usage: hands open notepad"
                app = parts[2]
                hands.execute({"type": "open_app", "app": app}, source=source)
                return f"Opened {app}."

            if cmd == "close":
                confirm = ("confirm" in parts) or ("yes" in parts)
                hands.execute({"type": "close_window", "confirm": confirm}, source=source)
                return "Closed the active window."

            return "Unknown hands command. Try: hands status | hands open notepad"

        except HandsError as exc:
            return str(exc)
        except Exception as exc:
            log.exception("Hands command failed: %s", exc)
            return "Hands command failed. Check logs."

    # --- Stream/UI permission events (hotkeys publish these now; UI will later too) ---
    def handle_auto_reply_set(data):
        payload = data or {}
        enabled = bool(payload.get("enabled", False))
        intent_router.set_auto_reply(enabled)
        log.info("Auto-reply set -> %s", enabled)

    def handle_respond_now(_data):
        intent_router.trigger_respond_now()
        log.info("Respond-now requested")

    def handle_respond_suggestion(_data):
        intent_router.trigger_respond_to_suggestion()
        log.info("Respond-to-suggestion requested")

    bus.subscribe("ui.auto_reply.set", handle_auto_reply_set)
    bus.subscribe("ui.respond_now", handle_respond_now)
    bus.subscribe("ui.respond_suggestion", handle_respond_suggestion)

    # --- Vision events (prevents "No subscribers" warnings and completes wiring) ---
    def handle_vision_memory_set(data):
        payload = data or {}
        allowed = bool(payload.get("allowed", False))
        vision_state.memory_allowed = allowed
        try:
            # Sync the gate inside core.io.vision (so UI and hotkeys behave the same)
            from core.io import vision  # lazy import
            if hasattr(vision, "set_vision_memory_allowed"):
                vision.set_vision_memory_allowed(allowed)
        except Exception as exc:
            log.exception("Failed to sync vision memory gate: %s", exc)
        log.info("Vision -> Memory permission set -> %s", allowed)

    def handle_vision_watch_set(data):
        payload = data or {}
        enabled = bool(payload.get("enabled", False))
        vision_state.watch_enabled = enabled

        try:
            from core.io import vision  # lazy import

            if enabled:
                if not vision.is_watching():
                    def _cb(snap: Any) -> None:
                        try:
                            bus.publish("vision.snapshot", {
                                "source": "watch",
                                "image_path": getattr(snap, "image_path", None),
                                "capture_method": getattr(snap, "capture_method", None),
                                "ts": getattr(snap, "ts", None),
                                "detail": getattr(snap, "detail", None),
                                "active_window_title": getattr(snap, "active_window_title", None),
                                "active_process_name": getattr(snap, "active_process_name", None),
                                "active_pid": getattr(snap, "active_pid", None),
                            })
                        except Exception:
                            log.exception("Failed to publish vision.snapshot from watch callback")

                    vision.start_watch(
                        callback=_cb,
                        fps=_get_watch_fps(),
                        detail=_get_watch_detail(),
                        region=None,
                        save_debug_images=True,
                    )
            else:
                if vision.is_watching():
                    vision.stop_watch()
        except Exception as exc:
            log.exception("Failed to handle vision watch set: %s", exc)

        log.info("Vision Watch Mode set -> %s", enabled)

    def handle_vision_describe_now(data):
        payload = data or {}
        image_path = payload.get("image_path")

        # If this event came from UI later (no image_path), we can capture here.
        if not image_path:
            try:
                from core.io import vision  # lazy import
                if hasattr(vision, "describe_now"):
                    snap = vision.describe_now(detail="light", region=None, save_debug_image=True)
                else:
                    snap = vision.build_snapshot(detail="light", region=None, capture=True, save_debug_image=True)
                image_path = getattr(snap, "image_path", None)

                try:
                    bus.publish("vision.snapshot", {
                        "source": "describe_now",
                        "image_path": getattr(snap, "image_path", None),
                        "capture_method": getattr(snap, "capture_method", None),
                        "ts": getattr(snap, "ts", None),
                        "detail": getattr(snap, "detail", None),
                        "active_window_title": getattr(snap, "active_window_title", None),
                        "active_process_name": getattr(snap, "active_process_name", None),
                        "active_pid": getattr(snap, "active_pid", None),
                    })
                except Exception:
                    log.exception("Failed to publish vision.snapshot from describe_now")
            except Exception as exc:
                log.exception("Describe Now handler failed: %s", exc)

        vision_state.last_image_path = image_path
        vision_state.last_source = "describe_now"
        log.info("Describe Now received -> %s", image_path)

    def handle_vision_snapshot(data):
        payload = data or {}
        image_path = payload.get("image_path")
        source = payload.get("source")
        vision_state.last_image_path = image_path or vision_state.last_image_path
        vision_state.last_source = source or vision_state.last_source

        now = time.monotonic()
        if (now - vision_state._last_snapshot_log_monotonic) >= 5.0:
            vision_state._last_snapshot_log_monotonic = now
            log.info("Vision snapshot (%s) -> %s", source, image_path)

    def handle_vision_error(data):
        payload = data or {}
        where = payload.get("where", "unknown")
        log.warning("Vision error event received from: %s", where)

    bus.subscribe("vision.memory.set", handle_vision_memory_set)
    bus.subscribe("vision.watch.set", handle_vision_watch_set)
    bus.subscribe("vision.describe_now", handle_vision_describe_now)
    bus.subscribe("vision.snapshot", handle_vision_snapshot)
    bus.subscribe("vision.error", handle_vision_error)

    # --- Hands events (future UI/LLM tool-calls) ---
    def handle_hands_enable_set(data):
        payload = data or {}
        enabled = bool(payload.get("enabled", False))
        hands.set_enabled(enabled)
        log.info("Hands enabled -> %s", enabled)

    def handle_hands_dry_run_set(data):
        payload = data or {}
        dry = bool(payload.get("dry_run", False))
        hands.set_dry_run(dry)
        log.info("Hands dry_run -> %s", dry)

    def handle_hands_execute(data):
        payload = data or {}
        action = payload.get("action", None)
        source = str(payload.get("source", "event_bus"))

        if not isinstance(action, dict):
            bus.publish("hands.result", {"ok": False, "error": "hands.execute requires payload.action dict"})
            return

        try:
            out = hands.execute(action, source=source)
            bus.publish("hands.result", {"ok": True, "result": out})
        except Exception as exc:
            bus.publish("hands.result", {"ok": False, "error": str(exc)})

    bus.subscribe("hands.enable.set", handle_hands_enable_set)
    bus.subscribe("hands.dry_run.set", handle_hands_dry_run_set)
    bus.subscribe("hands.execute", handle_hands_execute)

    # Hotkeys
    start_hotkeys(event_bus=bus)

    # Voice listener (STT)
    start_voice_listener(bus)

    # Handle transcribed voice input
    def handle_voice_transcribed(data):
        payload = data or {}
        text = payload.get("text", "")

        if not isinstance(text, str):
            log.warning("voice.transcribed received non-string text: %s", type(text))
            return

        text = text.strip()

        if not text:
            log.info("voice.transcribed event received with empty text.")
            fallback = (
                "I heard something, but I could not understand the words. "
                "Please say it again."
            )
            try:
                print(f"\nAI (voice): {fallback}\n")
                tts.speak(fallback)
            except Exception as exc:
                log.exception("Error speaking fallback for empty STT text: %s", exc)
            return

        log.info("Voice input text: %r", text)

        # Hands commands (explicit only)
        hands_reply = maybe_handle_hands_command(text, source="voice")
        if hands_reply is not None:
            try:
                print(f"\nAI (voice): {hands_reply}\n")
                tts.speak(hands_reply)
            except Exception as exc:
                log.exception("Error speaking hands reply: %s", exc)
            return

        # Register voice input as a chat-style message
        intent_router.register_chat_message({
            "user": "voice",
            "text": text,
            "source": "voice_input",
        })

        try:
            final_reply = intent_router.route_intent(
                ai_engine=engine,
                vision_description=None,
            )
        except Exception as exc:
            log.exception("Error routing voice intent: %s", exc)
            return

        if final_reply:
            try:
                print(f"\nAI (voice): {final_reply}\n")
                tts.speak(final_reply)
            except Exception as exc:
                log.exception("Error printing or speaking AI voice reply: %s", exc)
        else:
            log.info("IntentRouter suppressed speech output.")

    # Subscribe to voice events
    bus.subscribe("voice.transcribed", handle_voice_transcribed)

    print_startup_banner(engine)
    interactive_loop(engine, preprocessor=lambda t: maybe_handle_hands_command(t, source="cli"), tts=tts, speak_cli=_env_truthy("COPARTNER_CLI_TTS", "1"))

    log.info("Shutting down Master AI Co-Partner core.main")


if __name__ == "__main__":
    main()
