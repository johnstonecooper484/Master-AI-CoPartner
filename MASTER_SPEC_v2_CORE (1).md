# MASTER_SPEC v2 â€“ CORE SYSTEM

This file describes the **core runtime** of the Master AI Coâ€‘Partner:
- Full folder tree (everything visible, nothing hidden)
- Where the brain, memory, voice, eyes, hands, and config live
- Singleâ€‘machine focused, but ready for multiâ€‘machine & cloud modes later

---

## 1. Full Project Tree (Canonical Layout)

```text
AI-CoPartner/
â”‚
â”œâ”€â”€ .env                          # Environment variables (LOCAL_LLM, API keys, flags)
â”œâ”€â”€ requirements.txt              # Python dependencies for dev/runtime
â”œâ”€â”€ README.md                     # Top-level project description
â”œâ”€â”€ LICENSE                       # License (to be chosen later)
â”‚
â”œâ”€â”€ config/                       # CONFIG, FLAGS, SECURITY, LOGGING SETUP
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py               # Modes, feature flags, defaults
â”‚   â”œâ”€â”€ machine_profiles.yaml     # single_pc / multi_node / server profiles
â”‚   â”œâ”€â”€ integrations.yaml         # Polly, other TTS/STT/LLM providers
â”‚   â”œâ”€â”€ security.yaml             # permissions, safety rules
â”‚   â”œâ”€â”€ logging.yaml              # logging formats & rotation settings
â”‚   â””â”€â”€ logs/                     # RUNTIME LOG OUTPUT
â”‚       â”œâ”€â”€ .gitkeep
â”‚       â”œâ”€â”€ ai_engine_*.log       # brain activity
â”‚       â”œâ”€â”€ core_main_*.log       # main loop, mode changes
â”‚       â”œâ”€â”€ voice_*.log           # STT/TTS, mic issues
â”‚       â””â”€â”€ task_engine_*.log     # future task planner / jobs
â”‚
â”œâ”€â”€ core/                         # MAIN RUNTIME / BRAIN / LOGIC
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Entry point: starts event bus, ai_engine, IO, HUD hooks
â”‚   â”œâ”€â”€ core_manager.py           # Orchestrates subsystems, startup/shutdown
â”‚   â”œâ”€â”€ ai_engine.py              # Core reasoning brain (single logical brain)
â”‚   â”œâ”€â”€ event_bus.py              # Pub/sub messaging between modules
â”‚   â”œâ”€â”€ command_handler.py        # Handles text/voice commands, system actions
â”‚   â”œâ”€â”€ intent_router.py          # "Think before you act" layer: routes intents & calls AI
â”‚   â”œâ”€â”€ hotkeys.py                # F12, global shortcuts, mode toggles
â”‚   â”œâ”€â”€ security_guard.py         # (Planned) safety checks before actions/commands
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                   # MEMORY BRAIN (short, long, skills, RAM buffer)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ memory_manager.py     # API to read/write/query all memory types
â”‚   â”‚   â”œâ”€â”€ memory_store.py       # (Optional) shared helpers / persistence logic
â”‚   â”‚   â”œâ”€â”€ short_term.json       # current session context (conversation buffer)
â”‚   â”‚   â”œâ”€â”€ long_term.json        # important long-term notes & facts
â”‚   â”‚   â”œâ”€â”€ skills_index.json     # index of known skills & metadata
â”‚   â”‚   â””â”€â”€ ram_buffer.json       # â€œvirtual RAMâ€ scratch space / working thoughts
â”‚   â”‚
â”‚   â”œâ”€â”€ skills/                   # SKILL LOGIC (CODE, not raw data)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ skill_manager.py      # registers skills, picks which to apply
â”‚   â”‚   â”œâ”€â”€ coding.py             # coding / dev helper skills
â”‚   â”‚   â”œâ”€â”€ gaming.py             # in-game helper skills
â”‚   â”‚   â”œâ”€â”€ life_assistant.py     # reminders, planning, life admin
â”‚   â”‚   â””â”€â”€ experimental/         # new or WIP skills
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ io/                       # EARS / EYES / HANDS / VOICE
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ listener.py           # High-level voice listener; wires F12 â†’ STT
â”‚       â”œâ”€â”€ vision.py             # (Planned) screen capture + OCR logic
â”‚       â”œâ”€â”€ kinect_adapter.py     # (Planned) Kinect / camera integration
â”‚       â”‚
â”‚       â”œâ”€â”€ controls/             # HANDS: MOUSE & KEYBOARD CONTROL
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ keyboard_mouse.py # Low-level mouse moves, clicks, typing
â”‚       â”‚   â”œâ”€â”€ macros.py         # Higher-level actions ("type note", "click button")
â”‚       â”‚   â””â”€â”€ game_integration.py # (Planned) per-game control helpers
â”‚       â”‚
â”‚       â””â”€â”€ speech/               # VOICE: STT & TTS PIPELINE
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ stt_engine.py     # Faster-Whisper (tiny/base) STT engine
â”‚           â”œâ”€â”€ tts_engine.py     # TTS selector, routes to local or Polly providers
â”‚           â”œâ”€â”€ voice_service.py  # Glue: mic â†’ STT â†’ intent â†’ AI â†’ TTS â†’ speaker
â”‚           â””â”€â”€ providers/        # Concrete TTS/STT provider backends
â”‚               â”œâ”€â”€ __init__.py
â”‚               â”œâ”€â”€ local_pyttsx3.py   # Offline TTS (primary)
â”‚               â”œâ”€â”€ amazon_polly.py    # Online TTS fallback (optional)
â”‚               â””â”€â”€ other_provider_stub.py # Placeholder for a 3rd TTS provider
â”‚
â”œâ”€â”€ data/                         # WHAT SHE LEARNS FROM & STORES (DATA ONLY)
â”‚   â”œâ”€â”€ memories/                 # Raw memory files (separate from core/memory code)
â”‚   â”‚   â”œâ”€â”€ pinned/               # user-pinned important items
â”‚   â”‚   â”œâ”€â”€ archive/              # archived / compacted older memories
â”‚   â”‚   â””â”€â”€ scratchpad/           # temporary notes / transient info
â”‚   â”‚
â”‚   â”œâ”€â”€ skills/                   # SKILL DATA (not Python code)
â”‚   â”‚   â”œâ”€â”€ coding/               # e.g., code snippets, style guides
â”‚   â”‚   â”œâ”€â”€ gaming/               # maps, boss notes, build guides
â”‚   â”‚   â””â”€â”€ life_admin/           # routines, checklists, templates
â”‚   â”‚
â”‚   â””â”€â”€ toolbox/                  # Resource docs the AI can read/learn from
â”‚       â”œâ”€â”€ docs/                 # general documentation, how-tos
â”‚       â”œâ”€â”€ guides/               # step-by-step guides (e.g., workflows)
â”‚       â”œâ”€â”€ reference/            # technical references, API docs
â”‚       â””â”€â”€ blueprints/           # high-level design docs used as "brain food"
â”‚
â”œâ”€â”€ ui/                           # HUD & SETUP UI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hud/                      # Main HUD (Control panel)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main_window.py        # main window / frame
â”‚   â”‚   â””â”€â”€ components/           # UI widgets
â”‚   â”‚       â”œâ”€â”€ status_panel.py   # CPU/memory/mode/status display
â”‚   â”‚       â”œâ”€â”€ mode_switcher.py  # offline / hybrid / multi-machine toggles
â”‚   â”‚       â”œâ”€â”€ voice_controls.py # mic on/off, TTS test, STT status
â”‚   â”‚       â”œâ”€â”€ machine_link_panel.py # connect/disconnect other PCs
â”‚   â”‚       â””â”€â”€ logs_viewer.py    # basic log viewing / error summary
â”‚   â”‚
â”‚   â””â”€â”€ setup_wizard/             # FIRST-RUN WIZARD
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ wizard.py             # controls wizard flow
â”‚       â””â”€â”€ steps/
â”‚           â”œâ”€â”€ welcome.py
â”‚           â”œâ”€â”€ mic_test.py
â”‚           â”œâ”€â”€ speaker_test.py
â”‚           â”œâ”€â”€ stt_tts_choice.py
â”‚           â”œâ”€â”€ mode_choice.py    # single PC / multi-machine / hybrid
â”‚           â””â”€â”€ summary.py
â”‚
â”œâ”€â”€ installers/                   # PACKAGING / INSTALLATION SCRIPTS
â”‚   â”œâ”€â”€ windows/
â”‚   â”‚   â”œâ”€â”€ build.bat             # build script for Windows
â”‚   â”‚   â””â”€â”€ nsis_script.nsi       # example NSIS installer script
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ prepare_env.py        # set up venv, install deps, sanity checks
â”‚   â”‚   â””â”€â”€ collect_assets.py     # gather resources for packaging
â”‚   â””â”€â”€ packaging_notes.md        # notes, options, future installer plans
â”‚
â”œâ”€â”€ tests/                        # TESTS (UNIT + INTEGRATION)
â”‚   â”œâ”€â”€ test_ai_engine.py
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â”œâ”€â”€ test_speech.py
â”‚   â”œâ”€â”€ test_controls.py
â”‚   â””â”€â”€ test_integration_flow.py
â”‚
â”œâ”€â”€ tmp/                          # TEMPORARY FILES (SAFE TO DELETE)
â”‚   â”œâ”€â”€ audio/                    # raw testing audio if needed
â”‚   â”œâ”€â”€ vision/                   # screenshots, OCR input
â”‚   â””â”€â”€ debug/                    # scratch debug output
â”‚
â””â”€â”€ docs/                         # DOCUMENTATION FILES ALREADY IN PROJECT
    â”œâ”€â”€ AI_CoPartner_Master_Blueprint.md
    â”œâ”€â”€ AI_COPARTNER_MASTER_CONTROL.txt
    â”œâ”€â”€ KINECT_CAMERA_INTEGRATION.md
    â”œâ”€â”€ PROJECT_NOTE.txt
    â””â”€â”€ PROJECT_GITHUB_POINTER.txt
```

---

## 2. Mental Model Summary (so you donâ€™t have to guess)

**Brain:**  
- `core/ai_engine.py` + `core/intent_router.py`

**Ears (hearing you):**  
- `core/io/listener.py`  
- `core/io/speech/stt_engine.py`

**Mouth (speaking to you):**  
- `core/io/speech/tts_engine.py`  
- `core/io/speech/providers/local_pyttsx3.py`  
- `core/io/speech/providers/amazon_polly.py`

**Eyes (seeing screen / future camera):**  
- `core/io/vision.py`  
- `core/io/kinect_adapter.py`

**Hands (mouse & keyboard):**  
- `core/io/controls/keyboard_mouse.py`  
- `core/io/controls/macros.py`

**Memory (short, long, skills, RAM buffer):**  
- `core/memory/memory_manager.py`  
- `core/memory/short_term.json`  
- `core/memory/long_term.json`  
- `core/memory/skills_index.json`  
- `core/memory/ram_buffer.json`  
- plus data mirrors in `data/memories` and `data/skills`

**Skills (what sheâ€™s good at):**  
- `core/skills/*` (code)  
- `data/skills/*` (supporting data)

**Config & security:**  
- `config/settings.py`  
- `config/machine_profiles.yaml`  
- `config/integrations.yaml`  
- `config/security.yaml`

**HUD / Control Panel:**  
- `ui/hud/*`  
- `ui/setup_wizard/*`

This is the **locked-in, canonical layout**.  
If we adjust it later, it will be an explicit version update, not a silent reshuffle.

---------------------------------------------------------------------------------------------------------------

ğŸ§  2. Quick sanity map (so you donâ€™t have to guess)

Just to anchor your brain:

Brain: core/ai_engine.py, core/intent_router.py

Ears: core/io/listener.py, core/io/speech/stt_engine.py

Mouth: core/io/speech/tts_engine.py + providers (pyttsx3 / Polly)

Eyes: core/io/vision.py, core/io/kinect_adapter.py

Hands: core/io/controls/keyboard_mouse.py, core/io/controls/macros.py

Memory: core/memory/* + data/memories/*

Skills: core/skills/* + data/skills/*

Toolbox / stuff she learns from: data/toolbox/*

HUD & setup: ui/hud/*, ui/setup_wizard/*

Security & config: config/*.py, config/*.yaml

This is now the canonical layout.
If we ever change it, we treat it like a version change, not a stealth rewrite.


---

## CORE FEATURE â€“ System Device Awareness & Default IO Behavior

### Goal
The AI Co-Partner must always be aware of the basic hardware and I/O devices available on the system, so it can:

- Know what it can actually use (camera, microphone, speakers, keyboard, mouse, etc.)
- Communicate clearly with the user about what is connected
- Default safely to the systemâ€™s default input/output devices
- Help the user fix â€œI canâ€™t hear you / you canâ€™t hear meâ€ situations

This is a **core requirement**, not an optional add-on.

---

### 1. Device Types to Detect

On startup, and when requested, the Co-Partner should detect and keep track of:

- **Audio Output Devices**
  - Desktop speakers
  - Headsets (USB, 3.5mm, Bluetooth)
  - Earbuds (Bluetooth, wireless)
- **Audio Input Devices**
  - Built-in microphones
  - Headset microphones
  - USB / XLR mics
  - Bluetooth hands-free mics
- **Cameras**
  - Built-in webcams
  - USB cameras
- **Input Devices**
  - Keyboards (wired, wireless, Bluetooth)
  - Mice (wired, wireless, Bluetooth)
  - Other pointing devices (trackpads, etc.)

The Co-Partner does not manage drivers; it only uses what the OS says is present.

---

### 2. Default Behavior

By default:

- The Co-Partner should:
  - Use the **system default output device** for speaking (TTS).
  - Use the **system default input device** for listening (voice/STT).

- On first run, or when a new session starts, it should:
  - Do a quick self-check:
    - â€œI am using [Output Device Name] to speak.â€
    - â€œI am listening on [Input Device Name] for your voice.â€
  - Optionally say:
    - â€œIf you canâ€™t hear me or I canâ€™t hear you, ask me to list devices and weâ€™ll switch.â€

---

### 3. Device Listing & Selection (Core Logic)

When asked (voice or text), the Co-Partner should be able to:

1. **List devices** it sees, for example:

   - â€œFor speakers/output, I see:
     - Desktop Speakers
     - USB Gaming Headset
     - Earbuds XYZ (Stereo)

     For microphones/input, I see:
     - USB Mic
     - Earbuds XYZ (Hands-Free)
     - Laptop Built-In Mic.â€

2. **Offer to switch**:

   - â€œWhich one do you want to use for my voice?â€
   - â€œWhich one do you want me to listen on as your microphone?â€

3. **Apply the change** (where OS APIs allow):
   - Set new default input/output OR
   - Use that specific device just for the AIâ€™s own audio IO.

---

### 4. â€œI Donâ€™t Think You Can Hear Meâ€ Logic

If the AI detects:

- No output device available  
- Or the selected device suddenly disappears  
- Or repeated failed responses from the user when voice is expected  

Then it should:

1. Say (via text and any available audio):
   - â€œIâ€™m not sure you can hear me on the current device.â€
2. Suggest:
   - â€œAsk me to list audio devices and weâ€™ll pick a different one.â€
3. Optionally fall back to:
   - System default speakers
   - Or another known-good device if available

---

### 5. Hotplug Awareness (New Devices Plugged In)

Whenever possible (depending on OS and APIs):

- If a **new audio device, camera, or input device** appears:
  - The Co-Partner should notice and log it.
  - Optionally say:
    - â€œI see a new device connected: [Device Name].  
       Do you want to use this for my voice, your mic, or camera?â€

- If a device disappears:
  - Warn the user:
    - â€œThe device I was using is no longer available. Iâ€™ll switch back to the system default.â€

---

### 6. Safety & Stability

- The Co-Partner should:
  - Never rapidly switch devices without user intent.
  - Prefer stability over constant auto-changes.
  - Always explain:
    - What device itâ€™s using now
    - What device it wants to switch to (if any)

- In case of confusion:
  - Default to:
    - Systemâ€™s default speakers
    - Systemâ€™s default mic
  - And clearly say what happened.

---
